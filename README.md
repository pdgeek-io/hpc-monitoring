```
 __  __ ____   ____   __  __             _ _             _
|  \/  |  _ \ / ___| |  \/  | ___  _ __ (_) |_ ___  _ __(_)_ __   __ _
| |\/| | |_) | |     | |\/| |/ _ \| '_ \| | __/ _ \| '__| | '_ \ / _` |
| |  | |  __/| |___  | |  | | (_) | | | | | || (_) | |  | | | | | (_| |
|_|  |_|_|    \____| |_|  |_|\___/|_| |_|_|\__\___/|_|  |_|_| |_|\__, |
                                                                   |___/
   _____ _    _ _      _         _____ _             _
  |  ___| |  | | |    / |       / ____| |           | |
  | |_  | |  | | |    | |______| (___ | |_ __ _  ___| | __
  |  _| | |  | | |    | |______|\___ \| __/ _` |/ __| |/ /
  | |   | |__| | |____| |       ____) | || (_| | (__|   <
  |_|    \____/|______|_|      |_____/ \__\__,_|\___|_|\_\

```

<div align="center">

**ğŸš€ The Ultimate HPC Observability Platform ğŸš€**

[![Grafana](https://img.shields.io/badge/Grafana-11.3.0-orange?logo=grafana)](https://grafana.com)
[![Prometheus](https://img.shields.io/badge/Prometheus-2.54.1-red?logo=prometheus)](https://prometheus.io)
[![Docker](https://img.shields.io/badge/Docker-Powered-blue?logo=docker)](https://docker.com)
[![Ansible](https://img.shields.io/badge/Ansible-Automated-black?logo=ansible)](https://ansible.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

*Because if you can't measure it, is it even computing?* ğŸ¤“

[Quick Start](#-one-command-deployment) â€¢ [Architecture](#-the-full-stack) â€¢ [Features](#-what-youre-monitoring) â€¢ [Dashboards](#-pre-built-dashboards)

---

</div>

## ğŸ¯ What Is This?

Your HPC cluster is doing **amazing** things. But without monitoring, you're flying blind! This repo gives you:

- ğŸ“Š **Real-time metrics** from every component in your HPC stack
- ğŸ¨ **Beautiful dashboards** that make your ops team look like wizards
- ğŸ”” **Smart alerts** so you know about problems before your users do
- ğŸ¤– **Fully automated** deployment because ain't nobody got time for manual setup
- ğŸ³ **Docker-powered** observability stack that Just Worksâ„¢

**The best part?** One command deploys the entire monitoring infrastructure. Then sit back and watch the metrics roll in! ğŸ“ˆ

## ğŸ”­ What You're Monitoring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        YOUR HPC EMPIRE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  ğŸ–¥ï¸  COMPUTE NODES (Rocky Linux)           â†’  ğŸ“ˆ Node Exporter          â”‚
â”‚      â””â”€ CPU, RAM, I/O, Network, Disk                                    â”‚
â”‚                                                                          â”‚
â”‚  ğŸ® GPU NODES (NVIDIA)                     â†’  âš¡ DCGM Exporter          â”‚
â”‚      â””â”€ GPU Util, Memory, Power, Temp              (H100 ready!)        â”‚
â”‚                                                                          â”‚
â”‚  ğŸ“‹ JOB SCHEDULER (SLURM)                  â†’  ğŸ“Š SLURM Exporter         â”‚
â”‚      â””â”€ Queue depth, Running jobs, Wait times, Node allocation          â”‚
â”‚                                                                          â”‚
â”‚  ğŸ’¾ PARALLEL STORAGE                       â†’  ğŸ—„ï¸  Multiple Exporters    â”‚
â”‚      â”œâ”€ WEKA (distributed parallel FS)                                  â”‚
â”‚      â””â”€ MooseFS (fault-tolerant FS)                                     â”‚
â”‚                                                                          â”‚
â”‚  ğŸ­ DELL POWEREDGE SERVERS                 â†’  ğŸ”Œ iDRAC Exporter         â”‚
â”‚      â””â”€ Hardware health, Power, Thermal, RAID, PSU, Fans                â”‚
â”‚                                                                          â”‚
â”‚  ğŸŒ INFINIBAND FABRIC                      â†’  ğŸ“¡ UFM Exporter           â”‚
â”‚      â””â”€ Topology, bandwidth, errors                                     â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š Port Reference Card

Keep this handy when troubleshooting!

| ğŸ¯ Component | ğŸšª Port | ğŸ“ Endpoint | ğŸ’¡ What It Does |
|--------------|---------|-------------|-----------------|
| **Node Exporter** | `9100` | `/metrics` | System vitals (CPU, RAM, disk) |
| **NVIDIA DCGM** | `9400` | `/metrics` | GPU go brrrr metrics |
| **SLURM Exporter** | `9091` | `/metrics` | Job queue stats |
| **WEKA Exporter** | `9101` | `/metrics` | Parallel storage perf |
| **MooseFS Exporter** | `9105` | `/metrics` | Distributed FS health |
| **iDRAC Exporter** | `9610` | `/metrics` | Hardware health check |
| **Grafana** | `3000` | `/` | The pretty dashboards âœ¨ |
| **Prometheus** | `9090` | `/graph` | Time series database |
| **Loki** | `3100` | `/` | Log aggregation |
| **Tempo** | `3200` | `/` | Distributed tracing |

## ğŸ—‚ï¸ Repository Structure

```
hpc-monitoring/
â”‚
â”œâ”€â”€ ğŸ¤– ansible/                         # Automation magic happens here
â”‚   â”œâ”€â”€ ğŸ“‹ inventory                    # Your infrastructure map
â”‚   â”œâ”€â”€ ğŸ“š playbooks/
â”‚   â”‚   â”œâ”€â”€ setup_monitoring.yml        # ğŸš€ THE BIG ONE - deploys everything!
â”‚   â”‚   â”œâ”€â”€ hpc_fullstack_monitoring.yml # Full HPC stack
â”‚   â”‚   â”œâ”€â”€ grafana_stack.yml           # Observability platform
â”‚   â”‚   â””â”€â”€ validate_endpoints.yml      # Health check everything
â”‚   â””â”€â”€ ğŸ­ roles/
â”‚       â”œâ”€â”€ node_exporter/              # Rocky Linux + CPU feature detection
â”‚       â”œâ”€â”€ nvidia_dcgm_exporter/       # GPU metrics (H100 ready!)
â”‚       â”œâ”€â”€ slurm_exporter/             # Job scheduler insights
â”‚       â”œâ”€â”€ wekafs_exporter/            # Parallel storage metrics
â”‚       â”œâ”€â”€ moosefs_exporter/           # Distributed FS monitoring
â”‚       â”œâ”€â”€ idrac_exporter/             # Dell hardware health
â”‚       â””â”€â”€ grafana_stack/              # The full observability stack
â”‚
â”œâ”€â”€ ğŸ³ docker/
â”‚   â””â”€â”€ grafana-stack/                  # Containerized monitoring platform
â”‚       â”œâ”€â”€ docker-compose.yml          # One file to rule them all
â”‚       â”œâ”€â”€ prometheus/                 # Metrics database config
â”‚       â”œâ”€â”€ loki/                       # Log aggregation config
â”‚       â”œâ”€â”€ tempo/                      # Distributed tracing config
â”‚       â””â”€â”€ provisioning/               # Auto-setup datasources & dashboards
â”‚
â””â”€â”€ ğŸ“Š grafana_dashboards/              # Pre-built dashboard collection
    â”œâ”€â”€ hpc_unified_fullstack_dashboard.json  # â­ THE MEGA DASHBOARD
    â”œâ”€â”€ hpc_job_dashboard.json          # SLURM job queue analysis
    â”œâ”€â”€ poweredge_hardware_dashboard.json # Dell server health
    â””â”€â”€ hardware_dashboard.json         # General hardware metrics
```

## âš¡ One-Command Deployment

**TL;DR:** Deploy the entire monitoring stack in one shot:

```bash
# The nuclear option - deploys EVERYTHING! ğŸš€
ansible-playbook -i ansible/inventory ansible/playbooks/setup_monitoring.yml
```

This single command will:
- âœ… Deploy exporters to all HPC nodes
- âœ… Launch Grafana CE observability stack
- âœ… Auto-generate Prometheus configuration from your inventory
- âœ… Validate all endpoints are reachable
- âœ… Generate a health check report

Then open `http://your-monitoring-server:3000` and **BAM** - instant visibility! ğŸ‰

---

## ğŸ“‹ Step-by-Step Setup

### 1ï¸âƒ£ Define Your Infrastructure

Edit `ansible/inventory` to map your HPC empire:

```ini
[hpc1_compute_nodes]
compute[01:20].example.com    # Your compute army

[hpc1_gpu_nodes]
gpu[01:08].example.com        # The big iron ğŸ®

[hpc1_head_nodes]
head01.example.com            # The brain

[storage_weka]
weka[01:04].example.com       # Fast storage

[grafana]
monitor.example.com           # Mission control
```

ğŸ’¡ **Pro tip:** Use range notation `node[01:99]` to avoid typing 99 lines!

### 2ï¸âƒ£ Deploy Exporters to HPC Nodes

```bash
# Deploy to everything
ansible-playbook -i ansible/inventory ansible/playbooks/hpc_fullstack_monitoring.yml

# Or be selective
ansible-playbook -i ansible/inventory ansible/playbooks/hpc_fullstack_monitoring.yml \
  --limit gpu_nodes

# Or use tags for granular control
ansible-playbook -i ansible/inventory ansible/playbooks/hpc_fullstack_monitoring.yml \
  --tags compute,storage
```

Available tags: `compute`, `gpu`, `slurm`, `weka`, `moosefs`, `poweredge`, `baseline`

### 3ï¸âƒ£ Launch the Observability Stack

```bash
# Deploy Grafana CE full stack with Docker
ansible-playbook -i ansible/inventory ansible/playbooks/grafana_stack.yml
```

This deploys on your `[grafana]` host:
- Grafana (dashboards)
- Prometheus (metrics)
- Loki (logs)
- Tempo (traces)
- Alertmanager (notifications)

### 4ï¸âƒ£ Validate Everything Works

```bash
# Health check all the things!
ansible-playbook -i ansible/inventory ansible/playbooks/validate_endpoints.yml
```

Check the report at `/tmp/hpc_endpoint_validation_report.txt` for any issues.

---

## ğŸ­ Dell PowerEdge Hardware Monitoring

**Keep tabs on your metal!** Monitor server hardware health via iDRAC Redfish API.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ”Œ Dell PowerEdge Health Dashboard                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  âœ… System Health    â”‚ CPU Temp ğŸŒ¡ï¸  â”‚ Fan RPM ğŸŒ€          â”‚
â”‚  âš¡ Power Usage      â”‚ DIMM Status ğŸ’¾ â”‚ RAID Health ğŸ’¿      â”‚
â”‚  ğŸ”¥ Thermal Zones    â”‚ PSU Status ğŸ”‹  â”‚ Network NICs ğŸŒ     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Gets Monitored

| Component | Metrics | Why You Care |
|-----------|---------|--------------|
| ğŸ”‹ **Power** | Consumption, PSU capacity, efficiency | Catch power issues before UPS failover |
| ğŸŒ¡ï¸ **Thermal** | CPU/GPU/Inlet temps, thermal margins | Prevent thermal throttling |
| ğŸŒ€ **Cooling** | Fan speeds, status, redundancy | Know before a fan dies |
| ğŸ§  **CPU** | Per-socket utilization, features | Balance workloads |
| ğŸ’¾ **Memory** | DIMM health, correctable errors | Catch failing DIMMs early |
| ğŸ’¿ **Storage** | RAID status, drive health, predictive failures | No surprise disk failures! |
| ğŸ”Œ **PSU** | Redundancy, output power, health | Power supply peace of mind |

### Quick Setup

```bash
# 1. Add servers to inventory
cat >> ansible/inventory << EOF
[poweredge_servers]
poweredge[01:10].example.com
EOF

# 2. Configure iDRAC credentials
vim ansible/roles/idrac_exporter/defaults/main.yml
# Add your iDRAC IPs and credentials

# 3. Deploy!
ansible-playbook -i ansible/inventory ansible/playbooks/hpc_fullstack_monitoring.yml --tags poweredge
```

### ğŸ”’ Security Best Practice

**Don't hardcode passwords!** Use Ansible Vault:

```bash
# Encrypt your iDRAC password
ansible-vault encrypt_string 'SuperSecretPassword' --name 'password'

# Paste the encrypted output into defaults/main.yml
```

Create a read-only iDRAC user for monitoring:
1. Login to iDRAC web interface
2. Users â†’ Add New User
3. Username: `monitoring` (or whatever you like)
4. Privilege: **Read Only**
5. Enable account âœ…

---

## ğŸ§ Rocky Linux Love

This stack is **optimized** for Rocky Linux 8/9 (because RHEL clones deserve monitoring too!):

- âœ… **Enhanced collectors** - systemd, processes, cpu.info, diskstats, filesystem, and more
- ğŸ”’ **Security hardened** - NoNewPrivileges, ProtectHome, ProtectSystem
- ğŸ¯ **Auto-detection** - Knows when it's running on Rocky
- ğŸ§¬ **CPU features** - Detects AVX, AVX2, AVX-512, AES-NI, SSE4.2, FMA

Perfect for comparing 16G vs 17G PowerEdge hardware or tracking which nodes support what instruction sets!

---

## ğŸ¯ The Full Stack

**Everything. Everywhere. All at once.**

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         ğŸ¯ UNIFIED HPC MONITORING STACK              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚                 â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚ COMPUTE â”‚      â”‚   GPU   â”‚      â”‚ STORAGE â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      Rocky 9          NVIDIA            WEKA +
      AVX-512          DCGM 3.3         MooseFS
         â”‚                 â”‚                 â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚           ğŸ“Š PROMETHEUS                      â”‚
     â”‚           ğŸ“š LOKI (logs)                     â”‚
     â”‚           ğŸ” TEMPO (traces)                  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                 â”‚ GRAFANA â”‚ â† You are here!
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deploy the Universe

```bash
# Everything in one command
ansible-playbook -i ansible/inventory ansible/playbooks/hpc_fullstack_monitoring.yml
```

### Surgical Strikes (Tag-Based Deployment)

```bash
# Just compute nodes
ansible-playbook ... --tags compute

# Storage + scheduler
ansible-playbook ... --tags storage,slurm

# The works
ansible-playbook ... --tags baseline,gpu,storage,poweredge
```

**Available tags:**
- `compute` â†’ Rocky Linux nodes
- `gpu` â†’ NVIDIA GPUs
- `slurm`, `scheduler`, `jobs` â†’ Job queue
- `weka`, `moosefs`, `storage`, `filesystem` â†’ Parallel filesystems
- `poweredge`, `idrac`, `hardware`, `dell` â†’ Server health
- `baseline` â†’ Essential monitoring only

### ğŸ“Š Pre-Built Dashboards

We've done the hard work for you! Import these pre-built Grafana dashboards:

| Dashboard | What It Shows | When to Use |
|-----------|---------------|-------------|
| ğŸ¯ **hpc_unified_fullstack_dashboard.json** | THE BIG ONE - everything! | Daily operations, full visibility |
| ğŸ“‹ **hpc_job_dashboard.json** | SLURM queue deep dive | Job performance analysis |
| ğŸ­ **poweredge_hardware_dashboard.json** | Dell server hardware health | Hardware troubleshooting |
| ğŸ–¥ï¸ **hardware_dashboard.json** | General compute metrics | Node performance tuning |

**Import via:** Configuration â†’ Dashboards â†’ Import â†’ Upload JSON file

---

## ğŸ’¾ Storage System Monitoring

### MooseFS - Distributed Filesystem

```
  ğŸ§€ MooseFS Metrics
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Master: âœ… Online                   â”‚
  â”‚ Chunks: 12,456  Servers: 4/4        â”‚
  â”‚ Space: 2.4 PB / 3.0 PB used         â”‚
  â”‚ I/O: 12.3 GB/s read, 8.1 GB/s write â”‚
  â”‚ Clients: 142 connected              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Quick setup:**
```bash
# 1. Add to inventory
[storage_moosefs]
moosefs-master.example.com
moosefs-chunk[01:04].example.com

# 2. Configure master endpoint
vim ansible/roles/moosefs_exporter/defaults/main.yml
# Set: moosefs_master_host and moosefs_master_port

# 3. Deploy
ansible-playbook -i ansible/inventory ansible/playbooks/hpc_fullstack_monitoring.yml --tags moosefs
```

**Metrics tracked:** Space (total/used/available/trash), chunk servers, files/dirs, I/O ops, connected clients

### WEKA - Parallel Filesystem

Deploy with `--tags weka` - same simple process!

---

## ğŸ§¬ Hardware Generation Comparison

**Got old and new hardware?** Track performance differences between server generations!

```
  ğŸ“Š 16G vs 17G Comparison
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                 16G          17G      Î”          â”‚
  â”‚ AVX-512 VNNI:   âŒ           âœ…       +40% perf  â”‚
  â”‚ Power/Job:      285W         210W     -26%       â”‚
  â”‚ Thermal:        72Â°C         65Â°C     -7Â°C       â”‚
  â”‚ Job Time:       142s         98s      -31%       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CPU Features Tracked

The Node Exporter automatically detects and reports:
- **AVX, AVX2, AVX-512** (Foundation, DQ, BW, VL, VNNI)
- **AES-NI** - Hardware encryption
- **SSE4.2** - Streaming SIMD Extensions
- **FMA** - Fused Multiply-Add
- **BMI1/BMI2** - Bit Manipulation
- **VT-x/AMD-V** - Virtualization support

Query in Grafana:
```promql
node_cpu_feature{feature="avx512_vnni"}
```

**Research use cases:** Performance analysis, upgrade planning, power efficiency comparison, workload optimization

---

## ğŸ“‹ SLURM Job Monitoring

**Know your queue!** Track every job from submission to completion.

```
  SLURM Queue Status
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Running:   142  Pending:    67     â”‚
  â”‚ Completed: 1.2K Failed:     3      â”‚
  â”‚ Avg Wait:  4m   Nodes: 94/120     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Metrics You Get

âœ… Pending/running/completed/failed jobs
âœ… Queue wait times per partition
âœ… Node allocation and utilization
âœ… Resource consumption per job
âœ… Cross-correlation with compute metrics

### Example Queries

```promql
# How backed up is the queue?
rate(slurm_queue_jobs_pending[5m])

# Job success rate
rate(slurm_jobs_completed_total[5m]) / rate(slurm_jobs_total[5m])

# Average queue wait time trending
avg_over_time(slurm_queue_wait_seconds[1h])
```

**Use it to:** Optimize job submission, identify bottlenecks, understand scheduler behavior, predict resource needs

---

# ğŸš€ Docker-Based Deployment (Recommended)

## Grafana CE Full Observability Stack

**The whole enchilada in containers!** ğŸŒ¯

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ğŸ³ DOCKER-BASED MONITORING STACK                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                   â•‘
â•‘   ğŸ“Š GRAFANA 11.3.0          â†’  :3000   Dashboards & Viz         â•‘
â•‘   ğŸ“ˆ PROMETHEUS 2.54.1       â†’  :9090   Metrics (90d retention)  â•‘
â•‘   ğŸ“š LOKI 3.2.0              â†’  :3100   Logs (90d, 3x faster!)   â•‘
â•‘   ğŸ” TEMPO 2.6.0             â†’  :3200   Traces (30d)             â•‘
â•‘   ğŸ”” ALERTMANAGER 0.27.0     â†’  :9093   Smart alerting           â•‘
â•‘   ğŸ“ PROMTAIL                â†’         Log shipping              â•‘
â•‘                                                                   â•‘
â•‘   Built-in Exporters:                                            â•‘
â•‘   â€¢ Node Exporter 1.8.2      â€¢ cAdvisor 0.49.1                   â•‘
â•‘   â€¢ Pushgateway 1.9.0        â€¢ Blackbox 0.25.0                   â•‘
â•‘   â€¢ SNMP 0.26.0              â€¢ Process Exporter 0.8.3 â­         â•‘
â•‘   â€¢ StatsD 0.27.1 â­         â€¢ Image Renderer 3.11.3 â­          â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### ğŸ¯ Deploy Options

**Option A: Ansible (Production)**
```bash
# One command to rule them all
ansible-playbook -i ansible/inventory ansible/playbooks/grafana_stack.yml

# Gets deployed to: /opt/hpc-monitoring
# Systemd service: hpc-monitoring-stack
# Manage with: systemctl status hpc-monitoring-stack
```

**Option B: Docker Compose (Dev/Test)**
```bash
cd docker/grafana-stack

./start-stack.sh                    # ğŸš€ Launch!
docker-compose logs -f grafana      # ğŸ‘€ Watch the magic
docker-compose down                 # ğŸ›‘ Stop everything
```

### ğŸŒ Access Your Stack

| Service | URL | Login | What It Does |
|---------|-----|-------|--------------|
| ğŸ“Š **Grafana** | `http://server:3000` | admin/admin | Your command center |
| ğŸ“ˆ **Prometheus** | `http://server:9090` | - | Query metrics |
| ğŸ“š **Loki** | `http://server:3100` | - | Search logs |
| ğŸ” **Tempo** | `http://server:3200` | - | Trace requests |
| ğŸ”” **Alertmanager** | `http://server:9093` | - | Manage alerts |

> âš ï¸ **FIRST THING:** Change the default Grafana password! (admin/admin is so 2010)

### âš™ï¸ Configuration

**Prometheus targets auto-configured from inventory!** But if you need manual edits:

```bash
# Edit Prometheus config
vim docker/grafana-stack/prometheus/prometheus.yml

# Add your nodes
- job_name: 'my-hpc-cluster'
  static_configs:
    - targets: ['node01:9100', 'node02:9100', 'gpu01:9400']
      labels:
        cluster: 'production'
        tier: 'compute'
```

**Setup alerting:**
```bash
# Configure notification channels
vim docker/grafana-stack/alertmanager/alertmanager.yml

# Example: Slack notifications
receivers:
  - name: 'slack-hpc-ops'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
        channel: '#hpc-alerts'
        title: 'ğŸš¨ HPC Alert'
```

**Tweak retention:**
- **Prometheus**: 90 days, 50GB cap (in docker-compose.yml)
- **Loki**: 90 days (in loki-config.yml)
- **Tempo**: 30 days (in tempo.yml)

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ğŸ³ MONITORING SERVER (Docker Host)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚ GRAFANA â”‚â—„â”€â”€â”€â”¤PROMETHEUâ”‚â—„â”€â”€â”€â”¤  LOKI   â”‚                â”‚
â”‚   â”‚  :3000  â”‚    â”‚  :9090  â”‚    â”‚  :3100  â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                â”‚
â”‚        â”‚              â”‚              â”‚                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚  TEMPO  â”‚    â”‚ALERTMGR â”‚   â”‚PROMTAIL â”‚                â”‚
â”‚   â”‚  :3200  â”‚    â”‚  :9093  â”‚   â”‚         â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                              â”‚
â”‚   Built-in Exporters (monitoring this server):              â”‚
â”‚   â€¢ Node :9100  â€¢ cAdvisor :8080  â€¢ Blackbox :9115         â”‚
â”‚   â€¢ SNMP :9116  â€¢ Pushgateway :9091                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘    Scrapes metrics from all nodes    â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ–¥ï¸ HPC INFRASTRUCTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸ§ Compute Nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Node Exporter :9100          â”‚
â”‚  ğŸ® GPU Nodes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º DCGM Exporter :9400          â”‚
â”‚  ğŸ“‹ SLURM Scheduler â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º SLURM Exporter :9091         â”‚
â”‚  ğŸ’¾ WEKA Storage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º WEKA Exporter :9101          â”‚
â”‚  ğŸ§€ MooseFS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º MooseFS Exporter :9105       â”‚
â”‚  ğŸ­ Dell PowerEdge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º iDRAC Exporter :9610         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¾ Data Persistence & Backup

**All your data lives in Docker volumes - protect it!**

```bash
# See what you've got
docker volume ls | grep hpc-monitoring

# Backup everything (do this regularly!)
cd docker/grafana-stack
docker-compose down
docker run --rm \
  -v hpc-monitoring_prometheus_data:/data \
  -v $(pwd)/backups:/backup \
  ubuntu tar czf /backup/prometheus-backup-$(date +%Y%m%d).tar.gz /data

# Restore from backup
docker run --rm \
  -v hpc-monitoring_prometheus_data:/data \
  -v $(pwd)/backups:/backup \
  ubuntu tar xzf /backup/prometheus-backup-20250108.tar.gz -C /
docker-compose up -d
```

**Pro tip:** Set up a cron job to backup daily!

### ğŸ’ª Resource Requirements

| Environment | CPU | RAM | Disk | Notes |
|-------------|-----|-----|------|-------|
| **Testing/Dev** | 4 cores | 8 GB | 100 GB SSD | Good for kicking the tires |
| **Small HPC** | 8 cores | 16 GB | 500 GB SSD | <100 nodes |
| **Production** | 16+ cores | 32+ GB | 1+ TB SSD | For serious clusters |

ğŸ’¡ **Scale tip:** Prometheus needs ~2KB per metric per scrape. A 200-node cluster with 1000 metrics/node = ~400MB per scrape!

### ğŸ¯ The Three Pillars of Observability

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š METRICS        ğŸ“š LOGS         ğŸ” TRACES       â”‚
â”‚  (Prometheus)      (Loki)          (Tempo)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  What's broken?    Why is it       Where's the     â”‚
â”‚  Performance       broken?         bottleneck?     â”‚
â”‚  trends            Error msgs      Request flow    â”‚
â”‚  Resource usage    Debugging       Latency         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  ğŸ¨ GRAFANA      â”‚
            â”‚  Unified View    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**You get:**
1. ğŸ“ˆ **Metrics** - All HPC infrastructure, 90-day retention, PromQL queries
2. ğŸ“š **Logs** - System/app/SLURM logs, correlated with metrics, LogQL
3. ğŸ” **Traces** - Distributed tracing, integrated with logs & metrics
4. ğŸ¨ **Dashboards** - Pre-built HPC dashboards, auto-provisioned
5. ğŸš¨ **Alerts** - HPC-specific rules, multi-channel notifications

### ğŸ”§ Troubleshooting

**Stack won't start?**
```bash
# Check what's wrong
docker-compose logs <service-name>

# Disk full?
df -h

# Port conflicts?
sudo netstat -tlnp | grep -E '3000|9090|3100'
```

**Missing metrics?**
```bash
# Check Prometheus targets
curl http://your-server:9090/targets

# Test exporter directly
curl http://compute-node:9100/metrics

# Firewall blocking?
sudo firewall-cmd --list-all
```

**High memory usage?**
- â¬‡ï¸ Reduce scrape intervals (15s â†’ 30s)
- ğŸ“‰ Lower retention (90d â†’ 30d)
- ğŸ’° Add more RAM (it's 2025, RAM is cheap!)

**Loki queries slow?**
- ğŸ·ï¸ Use better label filtering
- â° Narrow time ranges
- ğŸ” Check `loki-config.yml` for indexing

For more help: `docker/grafana-stack/README.md`

---

# ğŸ‰ Version 2.0 - ALL THE UPGRADES!

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸš€ VERSION 2.0 IS HERE! ğŸš€                  â•‘
â•‘         Everything upgraded. Everything better. â„¢              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ†™ Major Version Upgrades

**We went through ALL the release notes so you don't have to!**

| Component | Before | After | ğŸ What You Get |
|-----------|--------|-------|-----------------|
| **Grafana** | 10.x | **11.3.0** | Faster dashboards, better correlations |
| **Prometheus** | 2.45 | **2.54.1** | Native histograms, 90d retention |
| **Loki** | 3.0 | **3.2.0** | **3x faster** queries! ğŸš€ |
| **Tempo** | 2.4 | **2.6.0** | Multi-protocol ingest, service graphs |
| **Node Exporter** | 1.5.0 | **1.8.2** | More collectors, better accuracy |
| **NVIDIA DCGM** | 2.4.10 | **3.3.9** | H100 support! ğŸ® |

## âœ¨ What's New

### â­ New Exporters

| Exporter | What It Does | Why You Want It |
|----------|--------------|-----------------|
| **Process Exporter 0.8.3** | Track SLURM, MPI, scientific apps | See what's consuming resources |
| **StatsD Exporter 0.27.1** | UDP metrics (port 9125) | Easy app instrumentation |
| **Image Renderer 3.11.3** | Auto-generate PNG/PDF reports | Email dashboards to management |

### ğŸš€ Performance Gains

```
Before:  [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 10s query time
After:   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 3s query time    â† 3x faster! (Loki 3.2)
```

- âš¡ **3x faster log queries** - Loki 3.2 is screaming fast
- ğŸ“¦ **90-day retention** - Up from 30 days (metrics & logs)
- ğŸ’¾ **50GB storage cap** - Auto-cleanup prevents disk fill
- ğŸ“Š **Native histograms** - Accurate percentiles in Prometheus
- ğŸ”— **Better trace-to-log correlation** - Find issues faster
- ğŸ“ˆ **Automatic service graphs** - See your architecture

## ğŸ”„ Upgrade Now

**Option 1: The "I Trust You" Method**
```bash
cd docker/grafana-stack
docker-compose down          # ğŸ›‘ Stop everything
docker-compose pull          # â¬‡ï¸  Get new versions
docker-compose up -d         # ğŸš€ Launch!
```

**Option 2: The Ansible Way (Recommended)**
```bash
# Automatically pulls latest, backs up configs
ansible-playbook -i ansible/inventory ansible/playbooks/grafana_stack.yml
```

**Option 3: With Custom Config**
```bash
# Customize first
cp docker/grafana-stack/.env.example docker/grafana-stack/.env
vim .env                     # Set your preferences

# Then deploy
cd docker/grafana-stack && docker-compose up -d
```

> ğŸ’¡ **No breaking changes!** All dashboards, alerts, and configs work as-is.

## ğŸ“¦ Complete Stack (14 Components)

**Core Platform:**
- Grafana 11.3.0
- Prometheus 2.54.1 (90d, 50GB cap)
- Loki 3.2.0 (90d, 3x speed boost)
- Tempo 2.6.0 (30d retention)
- Alertmanager 0.27.0
- Promtail (latest)

**Built-in Exporters:**
- Node Exporter 1.8.2
- cAdvisor 0.49.1
- Pushgateway 1.9.0
- Blackbox 0.25.0
- SNMP 0.26.0
- Process Exporter 0.8.3 â­
- StatsD Exporter 0.27.1 â­
- Image Renderer 3.11.3 â­

See `VERSIONS.md` for complete details, compatibility info, and rollback procedures.

---

## ğŸ“ Getting Help

**Documentation:**
- ğŸ“š Main docs: This README (you are here!)
- ğŸ³ Docker stack: `docker/grafana-stack/README.md`
- ğŸ“ Detailed setup: `docs/AUTOMATED_ENDPOINT_SETUP.md`
- ğŸ”– Version info: `VERSIONS.md`
- ğŸ’¡ Examples: `ansible/inventory.example`

**Quick Checks:**
```bash
# Validate your setup
ansible-playbook -i ansible/inventory ansible/playbooks/validate_endpoints.yml

# Check Prometheus targets
curl http://your-server:9090/targets | jq

# Test an exporter
curl http://compute-node:9100/metrics | grep node_cpu
```

**Common Issues:**
- Firewall blocking ports â†’ Check iptables/firewalld
- Exporters not running â†’ Check systemd status
- High memory usage â†’ Reduce scrape frequency or retention
- Missing metrics â†’ Verify inventory and Prometheus config

---

## ğŸ† Why This Monitoring Stack Rocks

âœ… **One-command deployment** - `setup_monitoring.yml` does it all
âœ… **Auto-configuration** - Prometheus config from Ansible inventory
âœ… **Latest versions** - Grafana 11.3, Prometheus 2.54, Loki 3.2
âœ… **Full observability** - Metrics, logs, traces in one place
âœ… **HPC-optimized** - Built for SLURM, GPUs, parallel storage
âœ… **Pre-built dashboards** - Import and go!
âœ… **Rocky Linux ready** - Optimized for RHEL clones
âœ… **H100 support** - Latest NVIDIA DCGM exporter
âœ… **Security hardened** - Ansible Vault for secrets
âœ… **Highly available** - Docker volumes, easy backups
âœ… **Battle-tested** - Proven on production HPC clusters

---

## ğŸ¤ Contributing

Got improvements? Found a bug? Want to add a new exporter?

1. Fork it
2. Create a feature branch
3. Make your changes
4. Submit a PR

**We love contributions!** Especially dashboards and alert rules.

---

## ğŸ“„ License

MIT License - See LICENSE file

---

<div align="center">

**Built with â¤ï¸ for HPC teams everywhere**

*Now go forth and monitor all the things!* ğŸ“Š

</div>
